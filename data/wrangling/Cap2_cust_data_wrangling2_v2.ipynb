{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Data Wrangling and Pre-processing\n",
    "In the first notebook, we removed all of the data that could be revealing of an individual purchaser. <br>\n",
    "In this notebook, we'll eliminate some unnecessary columns and create some more important feature columns that we can then look at in more detail in the Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Eliminate unnecessary columns, create some obvious features, minimize Nan values, and separate into Items, Orders, and Customers DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to the path with the raw csv file data\n",
    "\n",
    "# load the pickled version of the\n",
    "df = pd.read_csv(\"cust_pub4_pydata.csv\")\n",
    "# look at the first 10 rows of this file\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop all of the tax columns from this DF\n",
    "df.drop(\n",
    "    [\n",
    "        \"Tax 1 Name\",\n",
    "        \"Tax 1 Value\",\n",
    "        \"Tax 2 Name\",\n",
    "        \"Tax 2 Value\",\n",
    "        \"Tax 3 Name\",\n",
    "        \"Tax 3 Value\",\n",
    "        \"Tax 4 Name\",\n",
    "        \"Tax 4 Value\",\n",
    "        \"Tax 5 Name\",\n",
    "        \"Tax 5 Value\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we noticed from the first 10 rows that some of these values aren't filled. Let's use forward fill since that is the same order\n",
    "df[\"Paid at\"].fillna(method=\"ffill\", inplace=True, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert the \"Paid at\" column into datetime\n",
    "df[\"Paid at\"] = pd.to_datetime(df[\"Paid at\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop some more useless columns\n",
    "df.drop([\"Taxes\", \"Notes\", \"Note Attributes\", \"Cancelled at\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reciept Number is empty - drop that\n",
    "# Fullfilled at is missing a lot of values - we are using 'Paid at '\n",
    "# remove a few more columns that are too sparse to be useful in modeling\n",
    "df.drop(\n",
    "    [\"Fulfilled at\", \"Receipt Number\", \"Location\", \"Device ID\", \"Id\", \"Risk Level\"],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what currencies are used\n",
    "df[\"Currency\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's just USD ($) or NaN. Not worth keeping that column\n",
    "df.drop([\"Currency\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at Paid at vs. Created at\n",
    "df[[\"Paid at\", \"Created at\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those looks to be identical except for a 1-2 second lag for the payment. I'm good with dropping the paid at column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Paid at\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are using 'Created at' as the time stamp, let's convert it to date time\n",
    "# we need to convert the \"Paid at\" column into datetime\n",
    "df[\"Created at\"] = pd.to_datetime(df[\"Created at\"], infer_datetime_format=True, utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These look pretty good. Now, it's time to start filling in some of the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For financial status\n",
    "df[\"Financial Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it looks like the first line of an order has that Financial Status; we'll forward fill\n",
    "df[\"Financial Status\"].fillna(method=\"ffill\", inplace=True, limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same applies for Fulfillment Status\n",
    "df[\"Fulfillment Status\"].fillna(method=\"ffill\", inplace=True, limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same is true for Accepts Marketing\n",
    "df[\"Accepts Marketing\"].fillna(method=\"ffill\", inplace=True, limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Tags\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these look unnecessarily complicated, so we'll drop - or maybe not\n",
    "# df.drop(['Tags'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at Payment Reference\n",
    "df[\"Payment Reference\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop it\n",
    "df.drop([\"Payment Reference\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create one more feature that would be usable: total items in an order\n",
    "df[\"ITEMS\"] = df.groupby(\"Name\")[\"Lineitem quantity\"].transform(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ITEMS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many unique \"names\" are in the DF\n",
    "df[\"Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like the same number of \"subtotal\" and some other fields that are order specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let see if we can use the compare at price relative to the lineitem price as another feature\n",
    "df[\"compared\"] = (df[\"Lineitem compare at price\"] - df[\"Lineitem price\"]) / df[\"Lineitem price\"]\n",
    "# positive values mean the line item price is cheaper\n",
    "# this relative price is more important than the absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's convert this to a difference in price\n",
    "df[\"Lineitem compare at price\"] = df[\"Lineitem compare at price\"] - df[\"Lineitem price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the Dataframe <br>\n",
    "Right now, the items and the orders are each lines in the DataFrame; we are going to separate out the orders and items in the order into 2 separate dataframes:\n",
    "### 1. Order - contains the order information\n",
    "### 2. Items - line by line items contained in an order\n",
    "### 3. Customers - contains the sum of the orders and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Order DF by taking the first line of a name\n",
    "Order = df.groupby(\"Name\").first()\n",
    "\n",
    "# or I could do it groupby Name and then take the value that has a subtotal that is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at discount codes\n",
    "Order[\"Discount Code\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular discount codes are used largely enough that they could provide some value, but the largest code is used on 2% of all orders; discount codes are used on 11% of orders. I think it's best to just consider the discount amount to start and that's already contained in another column, so we'll drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order.drop([\"Discount Code\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orders, it shouldn't matter if that particular items is taxable, so we'll drop that or the fulfillment status\n",
    "Order.drop([\"Lineitem taxable\", \"Lineitem fulfillment status\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fill the payment method with \"unknown for the missing values\"\n",
    "Order[\"Payment Method\"].fillna(value=\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at Line item requires shipping\n",
    "Order[\"Lineitem requires shipping\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems reasonable enough; let's keep that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order[\"Lineitem sku\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop some more unnecessary info; line item name should be covered in the sku\n",
    "Order[\"Lineitem sku\"].fillna(value=Order[\"Lineitem name\"], inplace=True)\n",
    "Order.drop([\"Lineitem name\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer ID should be an integer - but this gets weird, so we'll skip it.\n",
    "# Order['Cust_ID'] = Order['Cust_ID'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find out how this shipping method looks\n",
    "Order[\"Shipping Method\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fill that shipping method with unknown - Shipping Method\n",
    "Order[\"Shipping Method\"].fillna(value=\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on some weird data, let's look at the source\n",
    "Order.Source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shopify_draft_order may just be draft orders that were used to test the system and not actual orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order[Order[\"Source\"] == \"shopify_draft_order\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look weird and are probably just tests. I'm dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order = Order[~(Order[\"Source\"] == \"shopify_draft_order\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepts marketing is currently \"yes\" or \"no\"; it's much better if we consider them as 1 and 0 respectively\n",
    "# then when we sum them up for multiple customer orders, it represents what went on better\n",
    "Order[\"Accepts Marketing\"].replace(to_replace=\"yes\", value=1, inplace=True)\n",
    "Order[\"Accepts Marketing\"].replace(to_replace=\"no\", value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I think that wraps it up for the Order DF\n",
    "\n",
    "### On to the Items DF that contains all of the line items in the orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every row in the dataframe represents a line item, so we'll keep them in\n",
    "Items = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That takes care of the Items DF\n",
    "\n",
    "### Still have to work on the Customer DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order[\"Cust_ID\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the customers based on these value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order[Order['Cust_ID'] == -2147483648]\n",
    "# this order showed up in 60k orders when we changed these from float to integer. I have non idea why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer DF by aggregating the orders DF over the Customer ID\n",
    "# 'Accepts Marketing': 'mode', 'Shipping Method': 'mode', 'Payment Method': 'mode',\n",
    "Cust = Order.groupby(\"Cust_ID\", as_index=False).agg(\n",
    "    {\n",
    "        \"Total\": [\"sum\", \"mean\", \"first\"],\n",
    "        \"Fulfillment Status\": \"count\",\n",
    "        \"Subtotal\": \"sum\",\n",
    "        \"Shipping\": \"sum\",\n",
    "        \"Refunded Amount\": \"sum\",\n",
    "        \"Accepts Marketing\": [\"sum\", \"first\"],\n",
    "        \"ITEMS\": [\"sum\", \"mean\", \"first\"],\n",
    "        \"Created at\": [\"first\", \"last\"],\n",
    "        \"Server\": \"first\",\n",
    "        \"Discount Amount\": \"sum\",\n",
    "        \"Vendor\": \"first\",\n",
    "        \"Employee\": \"first\",\n",
    "        \"Source\": \"first\",\n",
    "        \"ship_bill\": \"first\",\n",
    "        \"Area_Code\": \"first\",\n",
    "        \"Shipping Zip\": \"first\",\n",
    "        \"Lineitem sku\": \"first\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cust.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is exciting let's look at the first 10 rows\n",
    "Cust.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-indexing can be a pain. I will reduce this to a single index\n",
    "col = [\n",
    "    \"Cust_ID\",\n",
    "    \"Life_Total\",\n",
    "    \"Avg_Order\",\n",
    "    \"first_total\",\n",
    "    \"Orders\",\n",
    "    \"Sub_Total\",\n",
    "    \"Ship_Total\",\n",
    "    \"Refund_Total\",\n",
    "    \"Marketing_lf\",\n",
    "    \"Marketing_first\",\n",
    "    \"Total_Items\",\n",
    "    \"Avg_Items\",\n",
    "    \"first_items\",\n",
    "    \"first_order\",\n",
    "    \"last_order\",\n",
    "    \"server\",\n",
    "    \"Disc_Total\",\n",
    "    \"Vendor\",\n",
    "    \"Emp\",\n",
    "    \"Source\",\n",
    "    \"ship_bill\",\n",
    "    \"Area_Code\",\n",
    "    \"Ship_Zip\",\n",
    "    \"lead_sku\",\n",
    "]\n",
    "Cust.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is exciting let's look at the first 10 rows\n",
    "Cust.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cust[\"Orders\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order.groupby(\"Cust_ID\")[\"Created at\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order[\"1st\"] = Order[\"Created at\"] == Order[\"Created at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order['first_6mon'] = Order['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer DF by aggregating the orders DF over the Customer ID\n",
    "# 'Accepts Marketing': 'mode', 'Shipping Method': 'mode', 'Payment Method': 'mode',\n",
    "cust2 = Order.groupby(\"Cust_ID\", as_index=False).apply(lambda g: g.sort_values(\"Created at\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that does it for data wrangling. Let's export the data so that we can do EDA in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_timezone(df, date_cols):\n",
    "    for date_col in date_cols:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], utc=True)\n",
    "        df[date_col] = df[date_col].dt.tz_convert(\"US/Pacific\")\n",
    "        return df\n",
    "\n",
    "\n",
    "Cust = set_timezone(Cust, [\"first_order\", \"last_order\"])\n",
    "Items = set_timezone(Items, [\"Created at\"])\n",
    "Order = set_timezone(Order, [\"Created at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order.to_csv(\"../order.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Items.to_csv(\"../items.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cust.to_csv(\"../cust.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See you in the EDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
